{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed592307-32e5-4391-b502-8f4d5e843490",
   "metadata": {},
   "source": [
    "# Graded Exercise #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd732c-15e9-4fae-a76c-90e95664ee62",
   "metadata": {},
   "source": [
    "[EuroSAT](https://zenodo.org/records/7711810#.ZAm3k-zMKEA) is a land use and land cover classification dataset. The dataset is based on Sentinel-2 satellite imagery covering 13 spectral bands and consists of 10 Land Use and Land Cover (LULC) classes with a total of 27,000 labeled and geo-referenced images. \n",
    "\n",
    "Using the following code, you can create a DataFrame that includes columns detailing the center locations of the images and their corresponding Land Use and Land Cover (LULC) classes.\n",
    "\n",
    "Our task: Perform **supervised Machine Learning (ML)** on this dataset. Later we will use **Dask** in your implementation. We will follow the following key steps:\n",
    "- Create relevant features and analyse them using some visualizations and statistical tools. You can start with features representing the mean and range of spectral bands in these images. You are free to explore more relevant features.\n",
    "- Split the dataset into training, validation, and test sets.\n",
    "- Choose an appropriate ML algorithm.\n",
    "- Train and assess the model's performance.\n",
    "- Adjust the model's hyperparameters to optimize its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5c7c1-1390-40ce-a14b-51a5c59b3ccf",
   "metadata": {},
   "source": [
    "## 1. Creating the work space\n",
    "Import all the relevant folders and include the file plath to the where the imagery data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68a3821-c18c-4cbd-b5a7-11e948817e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc83a247-7c78-4869-8e5c-5347b1e844c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8077d511-76fa-40e6-8bbd-41af4642a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'EuroSAT_MS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1ae1a-ffa6-44cb-bcd2-9fe03aa7c6fa",
   "metadata": {},
   "source": [
    "## 2. Creating target variable data frame\n",
    "The goal of this excersize is to work on our understanding of machine learning concepts and try to put it into practise. Using the imagery provided by the professor we will create a df with the lat, long and respective land use classification. Land use classification is our target variable and the readings from the bands, as well as the derived features, will be used to create a model that would accurate identify land use classification in a new set up imager.\n",
    "\n",
    "The code given in this section gets the center coordiante from images. The coordiantes of the center of images makes up our data set. It is at these locations we'll be looking at the band readings and trying to predict land use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9177e922-2e76-4f62-9ac9-b7852ee7c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the center coordinate of the image\n",
    "def get_cent(filename):\n",
    "    with rasterio.open(filename) as dataset:\n",
    "        # Read the dataset's valid data mask as a ndarray.\n",
    "        mask = dataset.dataset_mask()\n",
    "\n",
    "        # Extract feature shapes and values from the array.\n",
    "        for geom, val in rasterio.features.shapes(\n",
    "                mask, transform=dataset.transform):\n",
    "\n",
    "            # Transform shapes from the dataset's own coordinate\n",
    "            # reference system to CRS84 (EPSG:4326).\n",
    "            geom = rasterio.warp.transform_geom(\n",
    "                dataset.crs, 'EPSG:4326', geom, precision=6)\n",
    "            ls = list(geojson.utils.coords(geom))\n",
    "            x = []\n",
    "            y = []\n",
    "            for row in ls:\n",
    "                x.append(row[0])\n",
    "                y.append(row[1])\n",
    "            cent = [min(y)+(max(y)-min(y))/2,min(x)+(max(x)-min(x))/2]\n",
    "    return cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cf1541-ad74-4d6a-b7ec-100e7dd88ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [ f.path for f in os.scandir(directory_path) if f.is_dir() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f85d1d3-b446-42c5-92ef-7c381c9cac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnualCrop 3000\n",
      "Forest 3000\n",
      "HerbaceousVegetation 3000\n",
      "Highway 2500\n",
      "Industrial 2500\n",
      "Pasture 2000\n",
      "PermanentCrop 2500\n",
      "Residential 3000\n",
      "River 2500\n",
      "SeaLake 3000\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"Lat\", \"Lon\", \"Class\"])\n",
    "for i in range(len(subfolders)):\n",
    "    image_path = subfolders[i]\n",
    "    class_name = os.path.basename(image_path)\n",
    "    all_images = [f for f in os.listdir(image_path) if os.path.isfile(join(image_path, f))]\n",
    "    print(class_name,len(all_images))\n",
    "    for j in range(len(all_images)):\n",
    "        cent = get_cent(image_path+'/'+all_images[j])\n",
    "        new_row = pd.DataFrame({\"Lat\": cent[0], \"Lon\": cent[1], \"Class\": class_name}, index=[0])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef89cc2-7649-4b93-94bd-a4cf8496f540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.035220</td>\n",
       "      <td>28.559055</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.085801</td>\n",
       "      <td>-1.829726</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.977294</td>\n",
       "      <td>4.239720</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.892610</td>\n",
       "      <td>4.089878</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.832851</td>\n",
       "      <td>18.084961</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26995</th>\n",
       "      <td>42.124618</td>\n",
       "      <td>12.194484</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26996</th>\n",
       "      <td>59.256125</td>\n",
       "      <td>15.611878</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>51.688627</td>\n",
       "      <td>4.137389</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>52.506092</td>\n",
       "      <td>8.335339</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>53.861029</td>\n",
       "      <td>9.028945</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lat        Lon       Class\n",
       "0      44.035220  28.559055  AnnualCrop\n",
       "1      39.085801  -1.829726  AnnualCrop\n",
       "2      48.977294   4.239720  AnnualCrop\n",
       "3      48.892610   4.089878  AnnualCrop\n",
       "4      51.832851  18.084961  AnnualCrop\n",
       "...          ...        ...         ...\n",
       "26995  42.124618  12.194484     SeaLake\n",
       "26996  59.256125  15.611878     SeaLake\n",
       "26997  51.688627   4.137389     SeaLake\n",
       "26998  52.506092   8.335339     SeaLake\n",
       "26999  53.861029   9.028945     SeaLake\n",
       "\n",
       "[27000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86684f0d-bfff-4275-a8f6-a7902c632de0",
   "metadata": {},
   "source": [
    "## 2. Creating relevant features \n",
    "Right now our data frame only contains the dependent variable, but no independent variables yet. We need to collect and create variables from the imagery to build out model. We wanted to include the max, median, range, and mode of all the band readings to have a broad understanding of what is going on at each observation point (centre coordinate). While the band readings are nice, we do not need to let the machine do all the work. There are several indexes that have been proven to help identify land use classification. The following indexes will be created as additional features: \n",
    "\n",
    "1.\tNormalized Difference Vegetation Index (NDVI)- this versatile index is used in agriculture, natural hazards such as landslides, land use/land cover change detection, environmental monitoring, water resources etc. to name a few. NDVI provides valuable information in wide range of applications making it an important feature to be studied.\n",
    "NDVI = (B8-B4) / (B8+B4).\n",
    "\n",
    "2.\tSAVI- Soil Adjusted Vegetation Index (SAVI) is used to correct Normalized Difference Vegetation Index (NDVI) for the influence of soil brightness in areas where vegetative cover is low. The higher the NDVI values (the same stands for SAVI) the denser (and healthier) the vegetation. But NDVI start saturating after the value of 0.7, while SAVI at this point is only 0.3. This means that SAVI can be better used in dense vegetation because it saturates less fast. \n",
    "For Sentinel-2 the formula is:\n",
    "(B08 - B04) / (B08 + B04 + L) * (1.0 + L); L = 0.428\n",
    "where: L is a soil brightness correction factor ranging from 0 to 1\n",
    "L = 1 low vegetation cover, L = 0 high vegetation cover, L = 0.5 intermediate vegetation cover.\n",
    "https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/savi/\n",
    "\n",
    "3.\tNormalised difference water index (NDWI)- is used to highlight open water features in a satellite image, allowing a water body to “stand out” against the soil and vegetation. The downside of the index is that it is sensitive to built structures, which can lead to overestimation of water bodies.\n",
    "For Sentinel 2 data:\n",
    "NDWI= (Band 3 – Band 8)/(Band 3 + Band 8)\n",
    "NDWI: Index Formula, Value Range, And Uses In Agriculture (eos.com)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d50abf-0c6c-4ac9-a668-15e33fb94091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract features\n",
    "def extract_spectral_features(filename):\n",
    "    with rasterio.open(filename) as dataset:\n",
    "        # Read all spectral bands\n",
    "        bands = [dataset.read(band) for band in range(1, dataset.count + 1)]\n",
    "\n",
    "        # Initialize lists to store statistics\n",
    "        band_stats = []\n",
    "\n",
    "        for band in bands:\n",
    "            # Calculate mean and range for each band\n",
    "            mean = np.nanmean(band)  # Calculate mean, handling NaN values\n",
    "            min_val = np.nanmin(band)  # Calculate minimum value, handling NaN values\n",
    "            max_val = np.nanmax(band)  # Calculate maximum value, handling NaN values\n",
    "            median = np.nanmedian(band) # Calculate median, handling NaN values\n",
    "            band_range = max_val - min_val\n",
    "\n",
    "            band_stats.append((mean,median, band_range))\n",
    "\n",
    "    return band_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ff634-2329-4346-b91c-baacd2d6fa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd62253-7693-4ad9-a690-5b4f701f0de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fbde5-46b4-4b24-b9ac-d511d07e5044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343d888-d793-4581-bfed-d30a67dc455c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edc541bd-6446-4548-8e24-053a2ed93f25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Split the data in training, test, and validation\n",
    "For our work it was important to have separate sets for training, validation, and testing. The primary reason was to reduce over fitting. The separation between these sets ensures that the model can perform well in real-world scenarios. Using the same data for all the three purposes can lead to over fitting as the model will simply memorize the data rather than making meaning results. We chose to do kmeans cross validations for our work as it is less biased than the simple train/test/valid split. This method of spliting data will ideally not result in overfitting, while still being relativelly simple to implement. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36a8bbd-6c76-4101-b6b8-14535d880e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea2fcd9-9b57-4820-9e0b-a61e2e33bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=10) \n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2b984-57e1-4b0a-8da0-02faf3b27b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834f718-d448-45fa-b6cb-9dd21cbcb102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ff9f323-eeda-4554-bc42-bd5cf27f3b02",
   "metadata": {},
   "source": [
    "## 4. Developing our model\n",
    "Random forest is a well-known machine learning model, commonly used for classification tasks. In recent studies random forest model was found to out preform artificial neural networks with the same task of land use classification [1] When working with Sentinel-2 specifically, as we are here, random forest was found to be the stand out model for land use/land cover classification [2]. For these reasons we chose random forest as our model.\n",
    "\n",
    "[1] https://www.frontiersin.org/articles/10.3389/frai.2022.964279/full#:~:text=We%20classified%20land%20use%20and,conducted%20by%20Tan%20et%20al.\n",
    "\n",
    "[2] Ge, G., Shi, Z., Zhu, Y., Yang, X., & Hao, Y. (2020). Land use/cover classification in an arid desert-oasis mosaic landscape of China using remote sensed imagery: Performance assessment of four machine learning algorithms. Global Ecology and Conservation, 22, e00971. https://www.sciencedirect.com/science/article/pii/S2351989420300202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdadfa8-c909-476e-87bd-ef544d0f92f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233459f9-1a7c-4a44-af5e-b6386b4eecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c539f3b-3d61-448a-bd3d-1991d9d4cf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402de59d-55af-4b55-bcb7-d92c089d9903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d8408-0151-401e-a975-4bc82d540299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f916a-ad46-4ea7-a6a5-1cf33b9c4a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb36166-6cb9-45c3-b3ea-a2f421007eae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d504492-e572-4bb0-9fca-b04884eea478",
   "metadata": {},
   "source": [
    "**Points of discussion**:\n",
    "- Can you explain the criteria and rationale behind the features you created? What other features you would select from these images in addition to the mean and range?\n",
    "   \n",
    "- Why is it important to have separate sets for training, validation, and testing? Which split did you consider and why?\n",
    "    \n",
    "- What factors influenced your choice of a specific machine learning algorithm?\n",
    "    \n",
    "- How did hyperparameter tuning impact the model's performance, and what were the final hyperparameter settings?\n",
    "- What is the impact of using DASK to solve this problem? What is the impact of changing DASK parameters like chunk size? You may consider checking CPU, memory usage, processing time, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a379732-8cf2-4e1c-9da2-96e23f415ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
